{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fine-Tune Pegasus Model (PRO version).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2ce9f8df8628440ba4f872c712cf00cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_777571ea300046bd9747c9d09903e0ed",
              "IPY_MODEL_648541becf6f4d0393b30ad49a84fef0",
              "IPY_MODEL_6aee6737a919435ea7b008705a48e46d"
            ],
            "layout": "IPY_MODEL_d0fbcbf9f2f94bc7964720a4f6e4ddd0"
          }
        },
        "777571ea300046bd9747c9d09903e0ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b3e530d5290411688bae623b4582fe0",
            "placeholder": "​",
            "style": "IPY_MODEL_364d4201557044e6a61fc0eb9ad3f04e",
            "value": "100%"
          }
        },
        "648541becf6f4d0393b30ad49a84fef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6e895ab00654430b0f861f669fd62e9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d45934674e84feab46e86383b47ebb0",
            "value": 1
          }
        },
        "6aee6737a919435ea7b008705a48e46d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bea99309db64fc1946a9f2b4e0be858",
            "placeholder": "​",
            "style": "IPY_MODEL_263e699669454941ab520f5414f2a987",
            "value": " 1/1 [00:03&lt;00:00,  3.42s/it]"
          }
        },
        "d0fbcbf9f2f94bc7964720a4f6e4ddd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b3e530d5290411688bae623b4582fe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "364d4201557044e6a61fc0eb9ad3f04e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6e895ab00654430b0f861f669fd62e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d45934674e84feab46e86383b47ebb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3bea99309db64fc1946a9f2b4e0be858": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "263e699669454941ab520f5414f2a987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Steps to save data as parquet"
      ],
      "metadata": {
        "id": "lDIdvnJG81Sb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "!pip install datasets transformers rouge_score nltk\n",
        "!pip install pyarrow\n",
        "# !pip install -q sentencepiece\n",
        "# !pip install rouge-score # google package version\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "3h2CN7ty8NWX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pprint import pprint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# nlp stuff\n",
        "import nltk\n",
        "\n",
        "# tf stuff\n",
        "import tensorflow_datasets as tfds \n",
        "import tensorflow as tf\n",
        "from transformers import PegasusTokenizer, TFPegasusForConditionalGeneration # pegasus\n",
        "from transformers import BartTokenizer, TFBartForConditionalGeneration # bart\n",
        "\n",
        "# pytorch dataset types\n",
        "import datasets\n",
        "from datasets.dataset_dict import DatasetDict\n",
        "from datasets import Dataset, load_metric, load_dataset\n",
        "\n",
        "# pytorch bart stuff\n",
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "PqqkCSxz8Paw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "write_path =\"/content/gdrive/MyDrive/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPO5KR598RsU",
        "outputId": "f9fae9ce-ace3-40bd-c364-69061d1b0630"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "raw_datasets = load_dataset(\"reddit\")\n",
        "print(f\"{(time.time() - start)/60} minutes elapsed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "2ce9f8df8628440ba4f872c712cf00cb",
            "777571ea300046bd9747c9d09903e0ed",
            "648541becf6f4d0393b30ad49a84fef0",
            "6aee6737a919435ea7b008705a48e46d",
            "d0fbcbf9f2f94bc7964720a4f6e4ddd0",
            "7b3e530d5290411688bae623b4582fe0",
            "364d4201557044e6a61fc0eb9ad3f04e",
            "e6e895ab00654430b0f861f669fd62e9",
            "2d45934674e84feab46e86383b47ebb0",
            "3bea99309db64fc1946a9f2b4e0be858",
            "263e699669454941ab520f5414f2a987"
          ]
        },
        "id": "RUrXXRpv8lnB",
        "outputId": "59d302d1-29a8-40bc-c5e0-5e2c904a507c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration default\n",
            "Reusing dataset reddit (/root/.cache/huggingface/datasets/reddit/default/1.0.0/98ba5abea674d3178f7588aa6518a5510dc0c6fa8176d9653a3546d5afcb3969)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ce9f8df8628440ba4f872c712cf00cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.06976009209950765 minutes elapsed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# slice it up and save it in chunks\n",
        "# doing 500k chunks\n",
        "total_obs = len(raw_datasets['train']['subreddit'])\n",
        "subset_chunk = np.arange(0, total_obs, step=500000)\n",
        "subset_chunk = np.append(subset_chunk, total_obs)\n"
      ],
      "metadata": {
        "id": "6IqVPb9B8nM5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_chunk(start, stop, filename):\n",
        "  pd.DataFrame({\n",
        "      'content': raw_datasets['train']['content'][start:stop], \n",
        "      'summary': raw_datasets['train']['summary'][start:stop], \n",
        "      'subreddit': raw_datasets['train']['subreddit'][start:stop]})\\\n",
        "    .to_parquet(filename)\n"
      ],
      "metadata": {
        "id": "8FBFcBdd8pHQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#write_path =\"/content/gdrive/MyDrive/Classes/W266_NLP/w266_reddit_summarization/data/reddit_parquet/\"\n",
        "write_path =\"/content/gdrive/MyDrive/\"\n",
        "\n",
        "for i in range(len(subset_chunk)-1):\n",
        "  print(f\"{i+1} of {len(subset_chunk)}\")\n",
        "  filename = write_path + 'reddit_data_0' + str(i) + '.parquet'\n",
        "  write_chunk(subset_chunk[i], subset_chunk[i+1], filename=filename)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhY5FqLF8yMO",
        "outputId": "b9791df8-edbe-4461-fa47-55795cd713b5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 of 9\n",
            "2 of 9\n",
            "3 of 9\n",
            "4 of 9\n",
            "5 of 9\n",
            "6 of 9\n",
            "7 of 9\n",
            "8 of 9\n",
            "CPU times: user 3min 35s, sys: 1min 31s, total: 5min 6s\n",
            "Wall time: 6min 57s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/gdrive/MyDrive\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiBMk_7DMm22",
        "outputId": "704393d7-6de8-433a-8530-4b4550d0a473"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the first parquet\n",
        "import pandas as pd\n",
        "df = pd.read_parquet('reddit_data_01.parquet')\n",
        "str(df['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "LFdTP43_V_Rz",
        "outputId": "c7bf3618-d2cc-4335-b991-b5a9ecc59420"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"0         Two posts and someone already linked that guid...\\n1         You run an email server at your house.  Total ...\\n2         Another funny dmt story:  My friend and i were...\\n3         I have been using the patch for five years. I ...\\n4         Dude, are you people still talking about this?...\\n                                ...                        \\n499995    In HTML (which is the skeleton of web pages), ...\\n499996    No offense, but this assumption makes you one ...\\n499997    meh, yeah i'll accept that. It helps in that c...\\n499998    Is it still going on? If so I would recommend ...\\n499999    I'm getting pain in my left knee, on the outsi...\\nName: content, Length: 500000, dtype: object\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create lists of the content and summary columns\n",
        "cont_list = df['content'].tolist()\n",
        "summ_list_small = df['summary'][:100].tolist()\n",
        "cont_list_small = df['content'][:100].tolist()\n",
        "summ_list = df['summary'].tolist()\n"
      ],
      "metadata": {
        "id": "U7hRI3O2ZAL2"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# all imports\n",
        "import os\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow_datasets as tfds \n",
        "#from transformers import TFAutoModelForSequenceClassification\n",
        "#from transformers import PegasusTokenizer, TFPegasusForConditionalGeneration"
      ],
      "metadata": {
        "id": "YLOIDJQYXHDs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers"
      ],
      "metadata": {
        "id": "oNyy936oXPAT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentencepiece"
      ],
      "metadata": {
        "id": "18DTC_NEXRBO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets"
      ],
      "metadata": {
        "id": "XIRiasbBXSnE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fine-tune Pegasus Model"
      ],
      "metadata": {
        "id": "QMF_EyVlXgSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Tokenize dataset to fine-tune model (https://huggingface.co/transformers/v4.9.2/training.html)\n",
        "import tensorflow as tf\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "from transformers import PegasusTokenizer, TFPegasusForConditionalGeneration\n",
        "tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-xsum\")"
      ],
      "metadata": {
        "id": "uprSrGiDXiBd"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Is this step necessary?\n",
        "#import nltk\n",
        "#nltk.download('punkt')\n",
        "\n",
        "#results = []\n",
        "#for sentence in cont_list_small:\n",
        "#    sentence_results = []\n",
        "#    for s in sentence:\n",
        "#        sentence_results.append(nltk.word_tokenize(sentence))\n",
        "#    results.append(sentence_results)"
      ],
      "metadata": {
        "id": "mDiRlkb6XkFQ"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Pretrain and compile model\n",
        "\n",
        "pega_model = TFPegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")\n",
        "tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-xsum\")\n",
        "\n",
        "pega_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=tf.metrics.SparseCategoricalAccuracy(),\n",
        ")\n",
        "\n",
        "pega_model.fit(cont_list, validation_data=summ_list, epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prPYnwdiXmUf",
        "outputId": "1aed7753-972e-49e5-d89b-374dd65bbd80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFPegasusForConditionalGeneration.\n",
            "\n",
            "All the layers of TFPegasusForConditionalGeneration were initialized from the model checkpoint at google/pegasus-xsum.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFPegasusForConditionalGeneration for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pega_model.save_pretrained(\"my_pega_model\")"
      ],
      "metadata": {
        "id": "D723Sh9pXrDr"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pega_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnzRmZ8eXsjd",
        "outputId": "57bf9af4-7171-494e-b476-8341c52fb263"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tf_pegasus_for_conditional_generation_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " model (TFPegasusMainLayer)  multiple                  569748480 \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 569,844,583\n",
            "Trainable params: 569,748,480\n",
            "Non-trainable params: 96,103\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test Model"
      ],
      "metadata": {
        "id": "b8fLXMeBXvnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(np.array2string(np.array(cont_list[0])), max_length=1024, truncation=True, return_tensors=\"tf\")\n",
        "inputs['input_ids'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzsWUjsRXy0T",
        "outputId": "35822654-3f8a-4940-ec5d-e74b7d54b9c9"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 295])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Summary\n",
        "summary_ids = pega_model.generate(inputs[\"input_ids\"], \n",
        "                              num_beams=4,\n",
        "                              no_repeat_ngram_size=2,\n",
        "                              min_length=20,\n",
        "                              max_length=50)"
      ],
      "metadata": {
        "id": "xr6ivBXhX3KK"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"content:\")\n",
        "print(cont_list[0])\n",
        "\n",
        "print(\"\\n\\true:\")\n",
        "print(summ_list[0])\n",
        "\n",
        "print(\"\\n\\nprediction:\")\n",
        "pprint(tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0], compact=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WX_pBECeaHow",
        "outputId": "9dceb23c-8363-46f9-dd8c-ef31b7a42efa"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content:\n",
            "Two posts and someone already linked that guide? I've gotta get faster! \n",
            " Completely agree with the above, spending a little extra goes a long way with DVD media. I've never had Taiyo Yuden (I'm in the UK and they aren't easy to get hold of) but I have had very good experiences with Verbatim and Sony. The reliability of the Sony discs versus the Infiniti discs I was using before actually paid for itself in how many burn failures I had (none in Sony's case). \n",
            " Some notes on DVD media - there are a lot of factors at play when determining reliability or even what discs you have. Some drives don't like certain manufacturer's discs, so don't assume what works for you will work for other people, or vice-versa. The reliability on the linked guide is determined from a lot of samples. \n",
            " The other point, which is important to bear in mind as you read the tables in that guide, is that most manufacturer's outsource manufacturing. You could buy two spindles with the same brand on the label but made by two different companies, which makes it hard to track reliability. Taiyo Yuden are recommended because they never outsource to factories of lower quality. Of course, this means if someone runs DVD Identifier on an AmazonBasics disc, whatever it is isn't necessarily what you'd get if you bought some.\n",
            "\n",
            "\true:\n",
            "don't buy cheap DVDRs\n",
            "\n",
            "\n",
            "prediction:\n",
            "('How much do you spend on a DVD and what is the reliability of the discs you '\n",
            " 'buy?')\n"
          ]
        }
      ]
    }
  ]
}